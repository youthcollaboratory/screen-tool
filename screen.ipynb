{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Load Term List CSV ---\n",
    "df = pd.read_csv('communication_screen_terms_v2.csv')\n",
    "\n",
    "# --- Constants & Helpers ---\n",
    "def clean_terms(term_string):\n",
    "    return [t.strip() for t in term_string.split(',') if t.strip()]\n",
    "\n",
    "# --- Screening Function (deduplicated + grouped info) ---\n",
    "def screen_text(input_text):\n",
    "    results_by_pos = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        term_map = {\n",
    "            'Primary': [row['Primary Term']],\n",
    "            'Secondary': clean_terms(row['Secondary Terms']),\n",
    "            'Tertiary': clean_terms(row['Tertiary Terms'])\n",
    "        }\n",
    "        for match_type, terms in term_map.items():\n",
    "            for term in terms:\n",
    "                for match in re.finditer(re.escape(term), input_text, re.IGNORECASE):\n",
    "                    key = (match.group(0).lower(), match.start())\n",
    "                    results_by_pos[key].append({\n",
    "                        'Flagged Term': match.group(0),\n",
    "                        'Match Type': match_type,\n",
    "                        'Primary Term': row['Primary Term'],\n",
    "                        'Category': row['Category'],\n",
    "                        'Flag Reason': row['Flag Reason'],\n",
    "                        'Executive Orders': row['Executive Orders'],\n",
    "                        'Position': match.start()\n",
    "                    })\n",
    "\n",
    "    priority = {'Primary': 0, 'Secondary': 1, 'Tertiary': 2}\n",
    "    grouped_results = []\n",
    "    for matches in results_by_pos.values():\n",
    "        matches_sorted = sorted(matches, key=lambda x: priority[x['Match Type']])\n",
    "        best = matches_sorted[0]\n",
    "        grouped_results.append({\n",
    "            'Flagged Term': best['Flagged Term'],\n",
    "            'Match Type': best['Match Type'],\n",
    "            'Flag Reason': best['Flag Reason'],\n",
    "            'Executive Orders': best['Executive Orders'],\n",
    "            'Position': best['Position'],\n",
    "            'Primary Terms': sorted(set(m['Primary Term'] for m in matches)),\n",
    "            'Categories': sorted(set(m['Category'] for m in matches))\n",
    "        })\n",
    "    return sorted(grouped_results, key=lambda x: x['Position'])\n",
    "\n",
    "# --- Highlighting Function ---\n",
    "def highlight_text(input_text, flagged):\n",
    "    matches = []\n",
    "    for entry in flagged:\n",
    "        term = entry['Flagged Term']\n",
    "        pattern = re.compile(re.escape(term), re.IGNORECASE)\n",
    "        for match in pattern.finditer(input_text):\n",
    "            matches.append({\n",
    "                'start': match.start(),\n",
    "                'end': match.end(),\n",
    "                'text': match.group(0),\n",
    "                'match_type': entry['Match Type'],\n",
    "                'reason': entry['Flag Reason'],\n",
    "                'eo': entry['Executive Orders'],\n",
    "                'primary_terms': entry['Primary Terms'],\n",
    "                'categories': entry['Categories']\n",
    "            })\n",
    "    matches.sort(key=lambda x: x['start'])\n",
    "    final_matches = []\n",
    "    last_end = -1\n",
    "    for match in matches:\n",
    "        if match['start'] >= last_end:\n",
    "            final_matches.append(match)\n",
    "            last_end = match['end']\n",
    "    result = \"\"\n",
    "    last_index = 0\n",
    "    for match in final_matches:\n",
    "        result += input_text[last_index:match['start']]\n",
    "        color = '#FFA500' if match['match_type'] in ['Primary', 'Secondary'] else '#FFFF00'\n",
    "        tooltip = (\n",
    "            f\"Reason for flagging: {match['reason']}\\n\"\n",
    "            f\"Primary Term(s): {', '.join(match['primary_terms'])}\\n\"\n",
    "            f\"Category(ies): {', '.join(match['categories'])}\\n\"\n",
    "            f\"Source: {match['eo']}\"\n",
    "        )\n",
    "        result += f'<mark style=\"background-color:{color}\" title=\"{tooltip}\">{match[\"text\"]}</mark>'\n",
    "        last_index = match['end']\n",
    "    result += input_text[last_index:]\n",
    "    return HTML(f\"<div style='white-space: pre-wrap; font-family: monospace;'>{result}</div>\")\n",
    "\n",
    "# --- Webpage Scraper ---\n",
    "def fetch_url_text(url):\n",
    "    print(\"Fetching URL:\", url)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for tag in soup(['script', 'style', 'header', 'footer', 'nav', 'aside']):\n",
    "            tag.decompose()\n",
    "        paragraphs = soup.find_all('p')\n",
    "        cleaned_paragraphs = [p.get_text(separator=' ', strip=True) for p in paragraphs if p.get_text(strip=True)]\n",
    "        body_text = \"\\n\\n\".join(cleaned_paragraphs)\n",
    "        print(\"Successfully fetched and parsed. Final text length:\", len(body_text))\n",
    "        return body_text\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return f\"Error fetching URL: {e}\"\n",
    "\n",
    "# --- Widgets ---\n",
    "text_input = widgets.Textarea(\n",
    "    placeholder='Paste your text here...',\n",
    "    layout=widgets.Layout(width='100%', height='150px'))\n",
    "\n",
    "url_input = widgets.Text(\n",
    "    placeholder='Or paste a URL to scan...',\n",
    "    layout=widgets.Layout(width='100%'))\n",
    "\n",
    "output_area = widgets.Output()\n",
    "highlight_area = widgets.Output()\n",
    "\n",
    "# --- Unified Handler ---\n",
    "def handle_screening(input_value, get_text_func, label):\n",
    "    output_area.clear_output()\n",
    "    highlight_area.clear_output()\n",
    "    flagged = []\n",
    "    with output_area:\n",
    "        if input_value.strip() == '':\n",
    "            print(f'No {label} provided.')\n",
    "            return\n",
    "        text = get_text_func(input_value)\n",
    "        if text.startswith(\"Error fetching URL:\"):\n",
    "            print(text)\n",
    "            return\n",
    "        print(\"Text length:\", len(text))\n",
    "        flagged = screen_text(text)\n",
    "        print(\"Flags found:\", len(flagged))\n",
    "        if flagged:\n",
    "            df_out = pd.DataFrame(flagged)[[\n",
    "                'Flagged Term', 'Match Type', 'Primary Terms', 'Categories', 'Executive Orders'\n",
    "            ]]\n",
    "            df_out.index += 1\n",
    "            display(df_out)\n",
    "        else:\n",
    "            print(\"No flagged terms found.\")\n",
    "    if flagged:\n",
    "        with highlight_area:\n",
    "            display(HTML(f\"<b>Highlighted {label.capitalize()} (hover for rationale and source):</b>\"))\n",
    "            display(highlight_text(text, flagged))\n",
    "\n",
    "# --- Buttons and Display ---\n",
    "text_button = widgets.Button(description='Screen Text', button_style='success')\n",
    "text_button.on_click(lambda _: handle_screening(text_input.value, lambda x: x, 'text'))\n",
    "\n",
    "url_button = widgets.Button(description='Screen URL', button_style='info')\n",
    "url_button.on_click(lambda _: handle_screening(url_input.value, fetch_url_text, 'URL'))\n",
    "\n",
    "display(widgets.VBox([text_input, text_button, url_input, url_button, output_area, highlight_area]))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}